{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: Expectation-Maximization\n",
    "\n",
    "In this assignment you will implement the Expectation-Maximization algorithm as learned in class.\n",
    "\n",
    "## Read the following instructions carefully:\n",
    "\n",
    "1. This jupyter notebook contains all the step by step instructions needed for this exercise.\n",
    "2. Write vectorized code whenever possible.\n",
    "3. You are responsible for the correctness of your code and should add as many tests as you see fit. Tests will not be graded nor checked.\n",
    "4. Write your functions in the provided `hw4.py` python module only. All the logic you write is imported and used in this jupyter notebook.\n",
    "5. You are allowed to use functions and methods from the [Python Standard Library](https://docs.python.org/3/library/) and [numpy](https://www.numpy.org/devdocs/reference/) only. Any other imports detected in `hw4.py` will earn you the grade of 0, even if you only used them for testing.\n",
    "6. You are, however, encouraged to use E-M implementation from sklearn to test your code in the notebook. DO NOT import sklearn in `hw4.py`.\n",
    "6. Your code must run without errors. During the environment setup, you were given a specific version of `numpy` to install. Changes of the configuration we provided are at your own risk. Code that cannot run will also earn you the grade of 0.\n",
    "7. Write your own code. Cheating will not be tolerated. \n",
    "8. Submission includes the `hw4.py` file and this notebook. Answers to qualitative questions should be written in markdown cells (with $\\LaTeX$ support).\n",
    "9. You are allowed to include additional functions.\n",
    "10. Submission: zip containing only the completed jupyter notebook and the python file `hw4.py`. Do not include the data or any directories. Name the file `ID1_ID2.zip` and submit *only one copy* of the assignment.\n",
    "\n",
    "\n",
    "## In this exercise you will perform the following:\n",
    "\n",
    "1. Use the sklearn library to fit two gaussians and plot the results\n",
    "2. Implement E-M algorithm and apply it on a dataset with unknown distribution \n",
    "\n",
    "## important notes:\n",
    "1. You will only be graded for the code in `hw4.py`\n",
    "2. Each function you write will be tested automatically with python unit tests. you are not allowed to change the input or output formats of the functions.\n",
    "3. In order to avoid variable type mistakes and make sure your format is correct, several tests were added for you within this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the notebook automatically reload external python modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hw4.hw4 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Warmup - fitting gaussians with sklearn (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "We will create a dataset composed of two gaussians and learn their parameter using sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_WIDTH_IN_SIGMA = 3\n",
    "mu1 = -1\n",
    "sigma1 = 1\n",
    "x1 = np.linspace(mu1 - PLOT_WIDTH_IN_SIGMA * sigma1, mu1 + PLOT_WIDTH_IN_SIGMA * sigma1, 1000)\n",
    "y1 = norm.pdf(x1, mu1, sigma1)\n",
    "\n",
    "mu2 = 5\n",
    "sigma2 = 2\n",
    "x2 = np.linspace(mu2 - PLOT_WIDTH_IN_SIGMA * sigma2, mu2 + PLOT_WIDTH_IN_SIGMA * sigma2, 1000)\n",
    "y2 = norm.pdf(x2, mu2, sigma2)\n",
    "\n",
    "plt.plot(x1, y1, color='red', lw=2, ls='-', alpha=0.5)\n",
    "plt.plot(x2, y2, color='blue', lw=2, ls='-', alpha=0.5)\n",
    "\n",
    "plt.xlim(min(mu1 - PLOT_WIDTH_IN_SIGMA * sigma1, mu2 - PLOT_WIDTH_IN_SIGMA * sigma2), max(mu1 + PLOT_WIDTH_IN_SIGMA * sigma1, mu2 + PLOT_WIDTH_IN_SIGMA * sigma2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will sample 500 instances from each gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "first_gaussian = norm.rvs(loc=mu1, scale=sigma1, size=500)\n",
    "second_gaussian = norm.rvs(loc=mu2, scale=sigma2, size=500)\n",
    "xs = np.concatenate((first_gaussian, second_gaussian))\n",
    "df = pd.DataFrame(data={'x': xs})\n",
    "ax = df.plot.hist(bins=70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the sample data we want to run EM in order to find the population distribution. <br>\n",
    "We first need to decide about the the distribution parameters. <br>\n",
    "After seeing the sample plot we can assume that the distribution of the population is GMM with 2 gaussians (remember that we won't see the first plot of the real distribution, but only the sample plot) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# TODO: init a GaussianMixture with 2 components\n",
    "# TODO: fit your model with the given data and predict the gaussian for each data point \n",
    "# hint: use sklearn.mixture.GaussianMixture ducomentation if you need help with find the relevant method\n",
    "\n",
    "z=None\n",
    "df['z'] = z # z is an array of size 1000 where z[i] is the number of the gaussian the i-th point belongs to (either 0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pred_vs_actual(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we almost found the original parameter only with 500 samples from each gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Implementing EM (90 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part you will implement the EM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the data\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# TODO: plot the data in order to decide about the parameters of the distribution, use 70 bins\n",
    "ax = df.plot.hist(bins=70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: given the above plot, decide from how many guassian you think the data came from (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = get_num_of_gaussians()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implemented for you the EM wrraper algorithm.<br>\n",
    "This function calls to helper functions that you need to implement:<br>\n",
    "1. init - gussing the initial values of W, Mu, sigma\n",
    "2. expectation - perform the E-step\n",
    "3. maximization - perform the M-step\n",
    "4. calc_max_delta - calculating the maximal delta between each old and new parameters for the stopping condition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: implement function: `init` (20 points) - OK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "implement the init function in a way that makes sense given the data.\n",
    "notice that as part of the input you can use information about the data and the number of gaussians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple test for validation using the first dataset composed of 2 gaussians.\n",
    "# it is recommended to add more tests.\n",
    "\n",
    "w, mu, sigma = init(xs, 2)\n",
    "print (\"Gaussian weights: %s\" % w)\n",
    "print (\"Gaussians mu: %s\" % mu)\n",
    "print (\"Gaussians sigma: %s\" % sigma)\n",
    "\n",
    "print (\"\\nReturn type for w is correct: %s\" % (type(w) == np.ndarray))\n",
    "print (\"Return type for mu is correct: %s\" % (type(mu) == np.ndarray))\n",
    "print (\"Return type for sigma is correct: %s\" % (type(sigma) == np.ndarray))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: implement function: `expectation` (20 points) - ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we'll test the implementation on a simple dataset\n",
    "\n",
    "# preparing variables for test\n",
    "points = [-0.3, 0.3, 0.5]\n",
    "mu = np.array([-1, 5])\n",
    "sigma = np.array([1,2])\n",
    "w = np.array([0.5,0.5])\n",
    "expected_likelihood_array = np.array([[0.15612697, 0.00297806],\n",
    "                                      [0.0856843 , 0.00630455],\n",
    "                                      [0.0647588 , 0.00793491]])\n",
    "\n",
    "# compute likelihood dataframe\n",
    "likelihood_array = expectation(points, mu, sigma, w)\n",
    "\n",
    "# observe the results\n",
    "print (\"Computed array: %s÷ø\\n\" % likelihood_array)\n",
    "print (\"Expected array: %s\\n\" % expected_likelihood_array)\n",
    "\n",
    "\n",
    "# validate types\n",
    "print (\"Return type for likelihood_array is correct: %s\\n\" % (type(likelihood_array) == np.ndarray))\n",
    "\n",
    "# validate results\n",
    "print (\"Results are correct: %s\" % np.allclose(expected_likelihood_array, likelihood_array, atol=0.001))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: implement function: `maximization` (20 points) - ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll now test a simple dataset composed of 4 points, 3 points are from the first gaussian and the 4th is from the second gaussian\n",
    "\n",
    "points = [-0.9, -1, -1.1, 5]\n",
    "ranks = np.array([[1,0], [1,0], [1,0], [0,1]])\n",
    "\n",
    "w_new, mu_new, sigma_new = maximization(points, ranks)\n",
    "\n",
    "# observe the results\n",
    "w_new\n",
    "mu_new\n",
    "sigma_new\n",
    "\n",
    "# validate types\n",
    "print (\"Return type for w_new is correct: %s\" % (type(w_new) == np.ndarray))\n",
    "print (\"Return type for mu_new is correct: %s\" % (type(mu_new) == np.ndarray))\n",
    "print (\"Return type for sigma_new is correct: %s\\n\" % (type(sigma_new) == np.ndarray))\n",
    "\n",
    "\n",
    "# validate results\n",
    "expected_w_new = np.array([0.75, 0.25])\n",
    "expected_mu_new = np.array([-1.0,  5.0])\n",
    "expected_sigma_new = np.array([0.08164966, 0.0])\n",
    "print (\"Return value for w_new is correct: %s\" % np.allclose(expected_w_new, w_new, atol=0.001))\n",
    "print (\"Return value for  mu_new is correct: %s\" % np.allclose(expected_mu_new, mu_new, atol=0.001))\n",
    "print (\"Return value for sigma_new is correct: %s\" % np.allclose(expected_sigma_new, sigma_new, atol=0.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: implement function: `calc_max_delta` (10 points) - OK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: the delta is 0 if the old and new values are equal\n",
    "\n",
    "Hint: delta is a relative value (without a dimension) \n",
    "\n",
    "Return type: float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: implement function: `ExpectationMaximization` (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now, we'll run the EM algorithm on the dataset and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the EM algorithm\n",
    "res, mu, sigma, log_likelihood = expectation_maximization(df.x.tolist(), K, 1000, 0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we can observe that the log likelihood increases between the iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(log_likelihood)\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('log likelihood')\n",
    "plt.title('Log likelihood over iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ploting the output distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gmm(K, res, mu, sigma, df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
